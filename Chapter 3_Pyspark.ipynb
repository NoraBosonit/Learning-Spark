{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01699b81",
   "metadata": {},
   "source": [
    "# Capítulo 3: DataFrame API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d107b6",
   "metadata": {},
   "source": [
    "## Creando un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74708c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "# Create a DataFrame using SparkSession\n",
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"AuthorsAges\")\n",
    " .getOrCreate())\n",
    "# Create a DataFrame \n",
    "data_df = spark.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    " (\"TD\", 35), (\"Brooke\", 25)], [\"name\", \"age\"])\n",
    "# Group the same names together, aggregate their ages, and compute an average\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg(\"age\"))\n",
    "# Show the results of the final execution\n",
    "avg_df.show() #Calculo la media de las edades de las personas que se llaman igual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339523b",
   "metadata": {},
   "source": [
    "## Formas de definir un esquema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e80ca9",
   "metadata": {},
   "source": [
    "- Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b4e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField(\"author\", StringType(), False),\n",
    " StructField(\"title\", StringType(), False),\n",
    " StructField(\"pages\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac253f8",
   "metadata": {},
   "source": [
    "- Con DDL (Data Definition Language): más simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de8872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"author STRING, title STRING, pages INT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32250692",
   "metadata": {},
   "source": [
    "- Utilizando los dos **Esto no lo acabo de entender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895734e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n",
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Define schema for our data using DDL \n",
    "schema = \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING, `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\"\n",
    "# Create our static data\n",
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\",\n",
    "\"LinkedIn\"]],\n",
    " [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\",\n",
    "\"LinkedIn\"]],\n",
    " [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\",\n",
    "\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    " [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568,\n",
    "[\"twitter\", \"FB\"]],\n",
    " [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\",\n",
    "\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    " [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568,\n",
    "[\"twitter\", \"LinkedIn\"]]\n",
    " ]\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    " # Create a SparkSession\n",
    " spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"Example-3_6\")\n",
    " .getOrCreate())\n",
    " # Create a DataFrame using the schema defined above\n",
    " blogs_df = spark.createDataFrame(data, schema)\n",
    " # Show the DataFrame; it should reflect our table above\n",
    " blogs_df.show()\n",
    " # Print the schema used by Spark to process the DataFrame\n",
    " print(blogs_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85862dd3",
   "metadata": {},
   "source": [
    "**Para ver el esquema de un DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44a42c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Id,IntegerType,true),StructField(First,StringType,true),StructField(Last,StringType,true),StructField(Url,StringType,true),StructField(Published,StringType,true),StructField(Hits,IntegerType,true),StructField(Campaigns,ArrayType(StringType,true),true)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2db0f8",
   "metadata": {},
   "source": [
    "## Leyendo JSON "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b5953",
   "metadata": {},
   "source": [
    "**Traducción de Scala (no sé si está bien)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3311b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    " # Create a SparkSession\n",
    " spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"Example-3_7\")\n",
    " .getOrCreate())\n",
    " if args.length <= 0:\n",
    "    print(\"usage Example3_7 <file path to blogs.json>\")\n",
    "    #break\n",
    " #  Get the path to the JSON file\n",
    " jsonFile = args(0)\n",
    " # Definir el esquema de forma programática\n",
    " schema = StructType([StructField(\"Id\", IntegerType(), False),\n",
    "StructField(\"First\", StringType(), False),\n",
    " StructField(\"Last\", StringType(), False),\n",
    " StructField(\"Url\", StringType(), False),\n",
    " StructField(\"Published\", StringType(), False),\n",
    " StructField(\"Hits\", IntegerType(), False),\n",
    " StructField(\"Campaigns\", StringType(), False)])\n",
    "\n",
    " # Create a DataFrame by reading from the JSON file\n",
    " jsonFile\n",
    " blogs_DF = spark.read.schema(schema).json(jsonFile)\n",
    " # Show the DataFrame; it should reflect our table above\n",
    " blogs_DF.show(False)\n",
    " # Print the schema used by Spark to process the DataFrame\n",
    " print(blogs_DF.printSchema())\n",
    " print(blogs_DF.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e2a65",
   "metadata": {},
   "source": [
    "## Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6881db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'First', 'Last', 'Url', 'Published', 'Hits', 'Campaigns']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2b8eb",
   "metadata": {},
   "source": [
    "## Filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9e4814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reynold'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "blog_row = Row(6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", 255568, \"3/2/2015\",\n",
    " [\"twitter\", \"LinkedIn\"])\n",
    "# access using index for individual items\n",
    "blog_row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68c0d1",
   "metadata": {},
   "source": [
    "### Las filas se pueden crear utilizando DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9203054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Authors|State|\n",
      "+-------------+-----+\n",
      "|Matei Zaharia|   CA|\n",
      "|  Reynold Xin|   CA|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = [Row(\"Matei Zaharia\", \"CA\"), Row(\"Reynold Xin\", \"CA\")]\n",
    "authors_df = spark.createDataFrame(rows, [\"Authors\", \"State\"])\n",
    "authors_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9bdbb",
   "metadata": {},
   "source": [
    "## Leer y escribir DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb60728",
   "metadata": {},
   "source": [
    "### Leer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f01e7c",
   "metadata": {},
   "source": [
    "#### Si no especificas esquema, Spark lo predice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16c9076d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(CallNumber,StringType,true),StructField(UnitID,StringType,true),StructField(IncidentNumber,StringType,true),StructField(CallType,StringType,true),StructField(CallDate,StringType,true),StructField(WatchDate,StringType,true),StructField(CallFinalDisposition,StringType,true),StructField(AvailableDtTm,StringType,true),StructField(Address,StringType,true),StructField(City,StringType,true),StructField(Zipcode,StringType,true),StructField(Battalion,StringType,true),StructField(StationArea,StringType,true),StructField(Box,StringType,true),StructField(OriginalPriority,StringType,true),StructField(Priority,StringType,true),StructField(FinalPriority,StringType,true),StructField(ALSUnit,StringType,true),StructField(CallTypeGroup,StringType,true),StructField(NumAlarms,StringType,true),StructField(UnitType,StringType,true),StructField(UnitSequenceInCallDispatch,StringType,true),StructField(FirePreventionDistrict,StringType,true),StructField(SupervisorDistrict,StringType,true),StructField(Neighborhood,StringType,true),StructField(Location,StringType,true),StructField(RowID,StringType,true),StructField(Delay,StringType,true)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF = (spark\n",
    " .read\n",
    " .option(\"samplingRatio\", 0.001)\n",
    " .option(\"header\", True)\n",
    " .csv('C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\sf-fire-calls.csv'))\n",
    "#Con samplingRatio se infiere el esquema\n",
    "sampleDF.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9bf959",
   "metadata": {},
   "source": [
    "### Leyendo datos del departamento de bomberos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f77d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python, define a schema \n",
    "from pyspark.sql.types import *\n",
    "# Programmatic way to define a schema \n",
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    " StructField('UnitID', StringType(), True),\n",
    " StructField('IncidentNumber', IntegerType(), True),\n",
    " StructField('CallType', StringType(), True), \n",
    " StructField('CallDate', StringType(), True), \n",
    " StructField('WatchDate', StringType(), True),\n",
    " StructField('CallFinalDisposition', StringType(), True),\n",
    " StructField('AvailableDtTm', StringType(), True),\n",
    " StructField('Address', StringType(), True), \n",
    " StructField('City', StringType(), True), \n",
    " StructField('Zipcode', IntegerType(), True), \n",
    " StructField('Battalion', StringType(), True), \n",
    " StructField('StationArea', StringType(), True), \n",
    " StructField('Box', StringType(), True), \n",
    " StructField('OriginalPriority', StringType(), True), \n",
    " StructField('Priority', StringType(), True), \n",
    " StructField('FinalPriority', IntegerType(), True), \n",
    " StructField('ALSUnit', BooleanType(), True), \n",
    " StructField('CallTypeGroup', StringType(), True),\n",
    " StructField('NumAlarms', IntegerType(), True),\n",
    " StructField('UnitType', StringType(), True),\n",
    " StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    " StructField('FirePreventionDistrict', StringType(), True),\n",
    " StructField('SupervisorDistrict', StringType(), True),\n",
    " StructField('Neighborhood', StringType(), True),\n",
    " StructField('Location', StringType(), True),\n",
    " StructField('RowID', StringType(), True),\n",
    " StructField('Delay', FloatType(), True)])\n",
    "# Use the DataFrameReader interface to read a CSV file\n",
    "sf_fire_file = 'C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\sf-fire-calls.csv'\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c0bdfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CallNumber=20110016, UnitID='T13', IncidentNumber=2003235, CallType='Structure Fire', CallDate='01/11/2002', WatchDate='01/10/2002', CallFinalDisposition='Other', AvailableDtTm='01/11/2002 01:51:44 AM', Address='2000 Block of CALIFORNIA ST', City='SF', Zipcode=94109, Battalion='B04', StationArea='38', Box='3362', OriginalPriority='3', Priority='3', FinalPriority=3, ALSUnit=False, CallTypeGroup=None, NumAlarms=1, UnitType='TRUCK', UnitSequenceInCallDispatch=2, FirePreventionDistrict='4', SupervisorDistrict='5', Neighborhood='Pacific Heights', Location='(37.7895840679362, -122.428071912459)', RowID='020110016-T13', Delay=2.950000047683716)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b449629",
   "metadata": {},
   "source": [
    "#### Consultando datos del departamento de bomberos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bebc7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(new_fire_df\n",
    " .select(\"ResponseDelayedinMins\")\n",
    " .where(col(\"ResponseDelayedinMins\") > 5)\n",
    " .show(5, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fed9f",
   "metadata": {},
   "source": [
    "#### Eliminando y añadiendo columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a943cddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Python\n",
    "fire_ts_df = (new_fire_df\n",
    " .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))#Creo una columna con el formato que quiero\n",
    " .drop(\"CallDate\") #Elimino la anterior columna\n",
    " .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    " .drop(\"WatchDate\")\n",
    " .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"),\n",
    " \"MM/dd/yyyy hh:mm:ss a\"))\n",
    " .drop(\"AvailableDtTm\"))\n",
    "# Select the converted columns\n",
    "(fire_ts_df\n",
    " .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    " .show(5, False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d30532",
   "metadata": {},
   "source": [
    "### Escribir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee83e9e",
   "metadata": {},
   "source": [
    "**Se guarda el DataFrame en formato Parquet por defecto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6420891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(fire_df.write\\n    .format(\"parquet\")\\n    .saveAsTable(\"tbl_nm\"))'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"parquet_table = 'Tabla1'\n",
    "fire_df.write.format(\"parquet\").saveAsTable(parquet_table)\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"(fire_df.write\n",
    "    .format(\"parquet\")\n",
    "    .saveAsTable(\"tbl_nm\"))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d4785",
   "metadata": {},
   "source": [
    "## Operaciones y funciones varias (con consultas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62a5e0",
   "metadata": {},
   "source": [
    "- disctinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8baf2cff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(year('IncidentDate'))\n",
    " .distinct()\n",
    " .orderBy(year('IncidentDate'))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27262910",
   "metadata": {},
   "source": [
    "- groupBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c47a9a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----+\n",
      "|CallType                           |count|\n",
      "+-----------------------------------+-----+\n",
      "|Elevator / Escalator Rescue        |453  |\n",
      "|Marine Fire                        |14   |\n",
      "|Aircraft Emergency                 |36   |\n",
      "|Confined Space / Structure Collapse|13   |\n",
      "|Administrative                     |3    |\n",
      "|Alarms                             |19406|\n",
      "|Odor (Strange / Unknown)           |490  |\n",
      "|Citizen Assist / Service Call      |2524 |\n",
      "|HazMat                             |124  |\n",
      "|Watercraft in Distress             |28   |\n",
      "+-----------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .show(n=10, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388875a1",
   "metadata": {},
   "source": [
    "- orderBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5e68af3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull())\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .show(n=10, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10dad58",
   "metadata": {},
   "source": [
    "- max(), min(), avg(), sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e73e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions\n",
    "(fire_ts_df\n",
    " .select(sum(\"NumAlarms\"), avg(\"ResponseDelayedinMins\"),\n",
    " min(\"ResponseDelayedinMins\"), max(\"ResponseDelayedinMins\"))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae97be1",
   "metadata": {},
   "source": [
    "- stat(), describe(), correlation(), covariance(), sampleBy(), approxQuantile(), frequentItems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8763c970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010848528180278628\n"
     ]
    }
   ],
   "source": [
    "print(fire_ts_df\n",
    "         .corr(\"CallNumber\", 'Zipcode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09f463",
   "metadata": {},
   "source": [
    "## Ejercicios Departamento de bomberos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aba343",
   "metadata": {},
   "source": [
    "- ¿Cuáles fueron todos los diferentes tipos de llamadas de emergencia en 2018?\n",
    "- ¿Qué meses del año 2018 vieron la mayor cantidad de llamadas de emergencia?\n",
    "- ¿Qué vecindario en San Francisco generó la mayor cantidad de llamadas de emergencia en 2018?\n",
    "- ¿Qué vecindarios tuvieron los peores tiempos de respuesta a las llamadas de incendios en 2018?\n",
    "- ¿Qué semana del año en 2018 tuvo la mayor cantidad de llamadas de emergencia?\n",
    "- ¿Existe una correlación entre el vecindario, el código postal y el número de llamadas de bomberos?\n",
    "- ¿Cómo podemos usar archivos Parquet o tablas SQL para almacenar estos datos y volver a leerlos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1567ecf",
   "metadata": {},
   "source": [
    "**Columnas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9595f8a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CallNumber',\n",
       " 'UnitID',\n",
       " 'IncidentNumber',\n",
       " 'CallType',\n",
       " 'CallFinalDisposition',\n",
       " 'Address',\n",
       " 'City',\n",
       " 'Zipcode',\n",
       " 'Battalion',\n",
       " 'StationArea',\n",
       " 'Box',\n",
       " 'OriginalPriority',\n",
       " 'Priority',\n",
       " 'FinalPriority',\n",
       " 'ALSUnit',\n",
       " 'CallTypeGroup',\n",
       " 'NumAlarms',\n",
       " 'UnitType',\n",
       " 'UnitSequenceInCallDispatch',\n",
       " 'FirePreventionDistrict',\n",
       " 'SupervisorDistrict',\n",
       " 'Neighborhood',\n",
       " 'Location',\n",
       " 'RowID',\n",
       " 'ResponseDelayedinMins',\n",
       " 'IncidentDate',\n",
       " 'OnWatchDate',\n",
       " 'AvailableDtTS']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_ts_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f816f7",
   "metadata": {},
   "source": [
    "**Pregunta 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190a36b",
   "metadata": {},
   "source": [
    "¿Cuáles fueron todos los diferentes tipos de llamadas de emergencia en 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ca24cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            CallType|\n",
      "+--------------------+\n",
      "|Elevator / Escala...|\n",
      "|              Alarms|\n",
      "|Odor (Strange / U...|\n",
      "|Citizen Assist / ...|\n",
      "|              HazMat|\n",
      "|           Explosion|\n",
      "|        Vehicle Fire|\n",
      "|  Suspicious Package|\n",
      "|               Other|\n",
      "|        Outside Fire|\n",
      "|   Traffic Collision|\n",
      "|       Assist Police|\n",
      "|Gas Leak (Natural...|\n",
      "|        Water Rescue|\n",
      "|   Electrical Hazard|\n",
      "|      Structure Fire|\n",
      "|    Medical Incident|\n",
      "|          Fuel Spill|\n",
      "|Smoke Investigati...|\n",
      "|Train / Rail Inci...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preg_1 = (fire_ts_df\n",
    "                   .select(\"CallType\")\n",
    "                   .where((year(fire_ts_df.IncidentDate) == \"2018\") )\n",
    "                   .distinct()\n",
    "                   .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a2585",
   "metadata": {},
   "source": [
    "**Pregunta 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb01a0",
   "metadata": {},
   "source": [
    "¿Qué meses del año 2018 vieron la mayor cantidad de llamadas de emergencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5291d04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|month(IncidentDate)|count|\n",
      "+-------------------+-----+\n",
      "|                 10| 1068|\n",
      "|                  5| 1047|\n",
      "|                  3| 1029|\n",
      "|                  8| 1021|\n",
      "|                  1| 1007|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preg_2 = (fire_ts_df\n",
    "                   .where((year(fire_ts_df.IncidentDate) == \"2018\") )\n",
    "                   .groupBy(month(fire_ts_df.IncidentDate)).count()\n",
    "                   .orderBy(\"count\", ascending=False).show(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094b978",
   "metadata": {},
   "source": [
    "**Pregunta 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f261bb1",
   "metadata": {},
   "source": [
    "¿Qué vecindario en San Francisco generó la mayor cantidad de llamadas de emergencia en 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69b99fd2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|Neighborhood|count|\n",
      "+------------+-----+\n",
      "|  Tenderloin| 1393|\n",
      "+------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preg_3 = (fire_ts_df\n",
    "                   .where((year(fire_ts_df.IncidentDate) == \"2018\") )\n",
    "                   .groupBy(\"Neighborhood\").count()\n",
    "                   .orderBy(\"count\", ascending=False).show(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466eb378",
   "metadata": {},
   "source": [
    "**Pregunta 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8398af",
   "metadata": {},
   "source": [
    "¿Qué vecindarios tuvieron los peores tiempos de respuesta a las llamadas de incendios en 2018?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f95909a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|   Neighborhood|MediaTiempoRespuesta|\n",
      "+---------------+--------------------+\n",
      "|      Chinatown|   6.190314101143033|\n",
      "|       Presidio|   5.829227011272873|\n",
      "|Treasure Island|   5.453703684111436|\n",
      "+---------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preg_4 = (fire_ts_df\n",
    "                   .where((year(fire_ts_df.IncidentDate) == \"2018\") )\n",
    "                   .groupBy(\"Neighborhood\")\n",
    "                   .agg(avg(\"ResponseDelayedinMins\").alias(\"MediaTiempoRespuesta\"))\n",
    "                   .orderBy(\"MediaTiempoRespuesta\", ascending=False).show(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bb4d0",
   "metadata": {},
   "source": [
    "**Pregunta 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01917",
   "metadata": {},
   "source": [
    "¿Qué semana del año en 2018 tuvo la mayor cantidad de llamadas de emergencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d9ba1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|weekofyear(IncidentDate)|count|\n",
      "+------------------------+-----+\n",
      "|                      22|  259|\n",
      "+------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preg_5 = (fire_ts_df\n",
    "                   .where((year(fire_ts_df.IncidentDate) == \"2018\") )\n",
    "                   .groupBy(weekofyear(fire_ts_df.IncidentDate)).count()\n",
    "                   .orderBy(\"count\", ascending=False).show(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f09834",
   "metadata": {},
   "source": [
    "**Pregunta 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20906cd",
   "metadata": {},
   "source": [
    "¿Existe una correlación entre el vecindario, el código postal y el número de llamadas de bomberos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b03a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preg_6 = (fire_ts_df\n",
    "                   .groupBy('Neighborhood', 'Zipcode').count()\n",
    "                   .corr(\"count\", 'Zipcode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e64cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06771510346381854\n"
     ]
    }
   ],
   "source": [
    "print(preg_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b0eb3",
   "metadata": {},
   "source": [
    "**Pregunta 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9cd39f",
   "metadata": {},
   "source": [
    "¿Cómo podemos usar archivos Parquet o tablas SQL para almacenar estos datos y volver a leerlos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279f14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e8a606",
   "metadata": {},
   "source": [
    "## Dataset API: Leyendo archivo JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c78be81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+----+-------------+---------+--------------------+--------+-------------+--------+-----+---------+-------+----+-------------+\n",
      "|battery_level|c02_level|cca2|cca3|           cn|device_id|         device_name|humidity|           ip|latitude|  lcd|longitude|  scale|temp|    timestamp|\n",
      "+-------------+---------+----+----+-------------+---------+--------------------+--------+-------------+--------+-----+---------+-------+----+-------------+\n",
      "|            8|      868|  US| USA|United States|        1|meter-gauge-1xbYRYcj|      51| 68.161.225.1|    38.0|green|    -97.0|Celsius|  34|1458444054093|\n",
      "|            7|     1473|  NO| NOR|       Norway|        2|   sensor-pad-2n2Pea|      70|213.161.254.1|   62.47|  red|     6.15|Celsius|  11|1458444054119|\n",
      "+-------------+---------+----+----+-------------+---------+--------------------+--------+-------------+--------+-----+---------+-------+----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = (spark.read\n",
    ".json(\"C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\iot_devices.json\"))\n",
    "ds.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b605e",
   "metadata": {},
   "source": [
    "### Operaciones con el conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8156df6",
   "metadata": {},
   "source": [
    "Los Datasets no son soportados por Python por lo que los demás ejercicios hay que hacerlos en Scala."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
